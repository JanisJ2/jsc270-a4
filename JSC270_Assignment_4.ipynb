{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNExjaf3BlSxQjRqZ/SC2Ul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanisJ2/jsc270-a4/blob/main/JSC270_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github link: https://github.com/JanisJ2/jsc270-a4 \\\n",
        "Group member:\n",
        "- Christoffer Tan (1008740445)\n",
        "- Janis Joplin (10097515051)\n"
      ],
      "metadata": {
        "id": "nOx_bQ-RmImT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from google.colab import files\n",
        "import io\n",
        "import sys\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, roc_curve\n",
        "\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')  # Tokenizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eTJeDCkwpdC",
        "outputId": "42f84858-17f2-42dd-b39b-dec4ada19f46"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset from GitHub\n",
        "!wget \"https://raw.githubusercontent.com/JanisJ2/jsc270-a4/main/covid-tweets-train.csv\"\n",
        "!wget \"https://raw.githubusercontent.com/JanisJ2/jsc270-a4/main/covid-tweets-test.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GbY3rOzxcej",
        "outputId": "52dc1442-4683-4d9e-dd78-0ffa6f82cab8"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-29 19:45:55--  https://raw.githubusercontent.com/JanisJ2/jsc270-a4/main/covid-tweets-train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8991364 (8.6M) [text/plain]\n",
            "Saving to: ‘covid-tweets-train.csv.7’\n",
            "\n",
            "\rcovid-tweets-train.   0%[                    ]       0  --.-KB/s               \rcovid-tweets-train. 100%[===================>]   8.57M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-03-29 19:45:55 (121 MB/s) - ‘covid-tweets-train.csv.7’ saved [8991364/8991364]\n",
            "\n",
            "--2024-03-29 19:45:55--  https://raw.githubusercontent.com/JanisJ2/jsc270-a4/main/covid-tweets-test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 866735 (846K) [text/plain]\n",
            "Saving to: ‘covid-tweets-test.csv.7’\n",
            "\n",
            "covid-tweets-test.c 100%[===================>] 846.42K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-03-29 19:45:55 (44.0 MB/s) - ‘covid-tweets-test.csv.7’ saved [866735/866735]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the train data from CSV file\n",
        "train_data = pd.read_csv('covid-tweets-train.csv')\n",
        "train_data.columns = ['Label', 'Message', 'Sentiment']\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7ltXkzDaxl2K",
        "outputId": "601d46a0-6f0c-4c2d-8d7f-60733a1b85f9"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Label                                            Message Sentiment\n",
              "0      0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...         1\n",
              "1      1  advice Talk to your neighbours family to excha...         2\n",
              "2      2  Coronavirus Australia: Woolworths to give elde...         2\n",
              "3      3  My food stock is not the only one which is emp...         2\n",
              "4      4  Me, ready to go at supermarket during the #COV...         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-040ebbb9-77b5-45c4-a60a-30ca5dfc9ed7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-040ebbb9-77b5-45c4-a60a-30ca5dfc9ed7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-040ebbb9-77b5-45c4-a60a-30ca5dfc9ed7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-040ebbb9-77b5-45c4-a60a-30ca5dfc9ed7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d955e8c9-48c0-4198-8951-e1bcdbf83e2f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d955e8c9-48c0-4198-8951-e1bcdbf83e2f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d955e8c9-48c0-4198-8951-e1bcdbf83e2f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 41155,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11880,\n        \"min\": 0,\n        \"max\": 41154,\n        \"num_unique_values\": 41155,\n        \"samples\": [\n          14623,\n          23458,\n          8170\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41155,\n        \"samples\": [\n          \"So panic buying of soaps and toilet roll was bad enough, now the idiots are stockpiling alcohol ? whats wrong with people #CoronaVirus #StopPanicBuying #Covid_19\",\n          \"Talked to the excellent about about transmission risk at the supermarket As usual good hand hygiene avoid crowds and physical distancing are the way to go\",\n          \"\\\"Saudi Arabia is bracing for an economic downturn as oil prices plummet due to the #coronavirus pandemic\\\" https://t.co/PQ3eRX9euZ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2\",\n          \" England\\\"\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_missing_values(data):\n",
        "    data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "Qx1qire1nYTL"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean missing values from train_data\n",
        "filter_missing_values(train_data)"
      ],
      "metadata": {
        "id": "OfuQcylhs47B"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I"
      ],
      "metadata": {
        "id": "4cDujdn7m_6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a)"
      ],
      "metadata": {
        "id": "px6QeKNAxsWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the a data set, it will return the proportion of the observations belong the a sentiment type\n",
        "def proportion_of_sentiment(data, sentiment_type):\n",
        "    return (data['Sentiment'] == sentiment_type).sum() / len(data['Sentiment'])"
      ],
      "metadata": {
        "id": "P7glpGdjxtay"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"The proportion of the train observations belonging to sentiment type {i}: {proportion_of_sentiment(train_data, str(i))}\")"
      ],
      "metadata": {
        "id": "JEahDK0ps8WU",
        "outputId": "36e8103f-5437-48b1-c22b-5bfb8510e822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The proportion of the train observations belonging to sentiment type 0: 0.37414040288678835\n",
            "The proportion of the train observations belonging to sentiment type 1: 0.18739824557140428\n",
            "The proportion of the train observations belonging to sentiment type 2: 0.43841275241173183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b)"
      ],
      "metadata": {
        "id": "44JVVuDywCOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "yoXSDjI6kcsb"
      },
      "outputs": [],
      "source": [
        "def tokenize(data):\n",
        "    data['Tokens'] = data['Message'].apply(nltk.word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(train_data)\n",
        "train_data['Tokens'].head()"
      ],
      "metadata": {
        "id": "nclSR-_Ds_96",
        "outputId": "82450561-0165-498c-c2f6-47e851b42e1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...\n",
              "1    [advice, Talk, to, your, neighbours, family, t...\n",
              "2    [Coronavirus, Australia, :, Woolworths, to, gi...\n",
              "3    [My, food, stock, is, not, the, only, one, whi...\n",
              "4    [Me, ,, ready, to, go, at, supermarket, during...\n",
              "Name: Tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c)"
      ],
      "metadata": {
        "id": "TWccBIH4HjGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(data):\n",
        "    tokens_no_url = []\n",
        "\n",
        "    # for the tokens of each row, remove all occurences of url\n",
        "    for row in data['Tokens']:\n",
        "        tokens_no_url.append([re.sub('^http', '', t) for t in row])\n",
        "\n",
        "    # Replace our tokens with the url-removed version\n",
        "    data['Tokens'] = tokens_no_url"
      ],
      "metadata": {
        "id": "LjNabPjNHhj9"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_url(train_data)\n",
        "train_data['Tokens'].head()"
      ],
      "metadata": {
        "id": "WXD7m3fZtB-W",
        "outputId": "3ce7a7c9-680c-484c-ffe1-49fb6b2be2cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, s, :...\n",
              "1    [advice, Talk, to, your, neighbours, family, t...\n",
              "2    [Coronavirus, Australia, :, Woolworths, to, gi...\n",
              "3    [My, food, stock, is, not, the, only, one, whi...\n",
              "4    [Me, ,, ready, to, go, at, supermarket, during...\n",
              "Name: Tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d)"
      ],
      "metadata": {
        "id": "sWM2Bhwq_Hxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(data):\n",
        "    tokens_no_punct = []\n",
        "    # For the tokens of each row, remove all occurrences of punctuations (i.e. non-alphanumeric and non-whitespace)\n",
        "    for row in data['Tokens']:\n",
        "        tokens_no_punct.append([re.sub('[^\\w\\s]', '', t) for t in row])\n",
        "    # Replace our tokens with the punctuation-removed version\n",
        "    data['Tokens'] = tokens_no_punct\n",
        "\n",
        "def convert_to_lowercase(data):\n",
        "    lowercase_tokens = []\n",
        "    # For the tokens of each row, convert all strings to lowercase\n",
        "    for row in data['Tokens']:\n",
        "        lowercase_tokens.append([t.lower() for t in row])\n",
        "    # Replace our tokens with the lowercase version\n",
        "    data['Tokens'] = lowercase_tokens"
      ],
      "metadata": {
        "id": "0XIsIT2b_KI3"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_punctuation(train_data)\n",
        "convert_to_lowercase(train_data)\n",
        "train_data['Tokens'].head()"
      ],
      "metadata": {
        "id": "WxcrjJdutYNM",
        "outputId": "9dc6589a-6436-4afd-9a49-d9c6a229ad57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [, menyrbie, , phil_gahan, , chrisitv, s, , tc...\n",
              "1    [advice, talk, to, your, neighbours, family, t...\n",
              "2    [coronavirus, australia, , woolworths, to, giv...\n",
              "3    [my, food, stock, is, not, the, only, one, whi...\n",
              "4    [me, , ready, to, go, at, supermarket, during,...\n",
              "Name: Tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## e)"
      ],
      "metadata": {
        "id": "6J18_NrxIiDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming_tokens(data):\n",
        "    ### Stemming our dataset using PorterStemmer\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    stemmed_tokens = []\n",
        "    for row in data['Tokens']:\n",
        "      stemmed_tokens.append([stemmer.stem(t) for t in row])\n",
        "\n",
        "    data['Tokens'] = stemmed_tokens"
      ],
      "metadata": {
        "id": "WQj0e2CBK5TP"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming_tokens(train_data)\n",
        "train_data['Tokens'].head()"
      ],
      "metadata": {
        "id": "4MiS4d5UtZjD",
        "outputId": "55fbdf92-76ac-4ba4-f8c7-2d05a9b42fa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [, menyrbi, , phil_gahan, , chrisitv, s, , tco...\n",
              "1    [advic, talk, to, your, neighbour, famili, to,...\n",
              "2    [coronaviru, australia, , woolworth, to, give,...\n",
              "3    [my, food, stock, is, not, the, onli, one, whi...\n",
              "4    [me, , readi, to, go, at, supermarket, dure, t...\n",
              "Name: Tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## f)"
      ],
      "metadata": {
        "id": "Gu3KjZjPIj7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(data):\n",
        "    sw = stopwords.words('english')[:100]\n",
        "    tokens_no_sw = []\n",
        "    # For the tokens of each row, remove all occurrences of stopwords\n",
        "    for row in data['Tokens']:\n",
        "        tokens_no_sw.append([w for w in row if w not in sw])\n",
        "    # Replace our tokens with the stopwords-removed version\n",
        "    data['Tokens'] = tokens_no_sw"
      ],
      "metadata": {
        "id": "9CbMFoGFIlL1"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_stopwords(train_data)\n",
        "train_data['Tokens'].head()"
      ],
      "metadata": {
        "id": "PhPjg6fztbDM",
        "outputId": "26aeb20f-3eb6-4636-9fc8-965e5e2024b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [, menyrbi, , phil_gahan, , chrisitv, s, , tco...\n",
              "1    [advic, talk, neighbour, famili, exchang, phon...\n",
              "2    [coronaviru, australia, , woolworth, give, eld...\n",
              "3    [food, stock, not, onli, one, empti, , pleas, ...\n",
              "4    [, readi, go, supermarket, dure, , covid19, ou...\n",
              "Name: Tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## g)"
      ],
      "metadata": {
        "id": "XGXU1SuPLagm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_tokens_and_label(data):\n",
        "    return data['Tokens'].to_numpy(), data['Sentiment'].to_numpy()\n",
        "\n",
        "def override_fcn(doc):\n",
        "  # We expect a list of tokens as input\n",
        "  return doc\n",
        "\n",
        "def convert_to_vector(X):\n",
        "    # Count Vectorizer\n",
        "    count_vec = CountVectorizer(\n",
        "        analyzer='word',\n",
        "        tokenizer= override_fcn,\n",
        "        preprocessor= override_fcn,\n",
        "        token_pattern= None)\n",
        "\n",
        "    # Remember this output is a Scipy Sparse Array\n",
        "    counts = count_vec.fit_transform(X)\n",
        "    # print(counts.toarray())\n",
        "\n",
        "    # # Print this mapping as dictionary\n",
        "    # print(count_vec.vocabulary_)\n",
        "\n",
        "    # Print the length of the vocabulary\n",
        "    # print(f'The length of the vocabulary is {len(count_vec.vocabulary_)}')\n",
        "    return counts"
      ],
      "metadata": {
        "id": "VZxgHg0cUjH9"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = split_tokens_and_label(train_data)\n",
        "X_train = convert_to_vector(X_train)"
      ],
      "metadata": {
        "id": "6XFQvONltcdd",
        "outputId": "00c7cbba-1142-4202-e98b-1c0341bb8d04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [3 0 0 ... 0 0 0]\n",
            " ...\n",
            " [7 0 0 ... 0 0 0]\n",
            " [4 0 0 ... 0 0 0]\n",
            " [5 0 0 ... 0 0 0]]\n",
            "The length of the vocabulary is 74225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## h) `train_data`\n"
      ],
      "metadata": {
        "id": "Jzp_9vc7Lb9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_naive_bayes_model(X_data, y_data):\n",
        "    nb = MultinomialNB()\n",
        "    # Fit model to the data\n",
        "    nb.fit(X_data, y_data)\n",
        "    return nb\n",
        "\n",
        "def predict(X_data, y_data, mode):\n",
        "    nb = fit_naive_bayes_model(X_data, y_data)\n",
        "    y_preds = nb.predict(X_data)\n",
        "    print(f'Test accuracy with simple Naive Bayes on {mode} data: ', accuracy_score(y_data, y_preds))"
      ],
      "metadata": {
        "id": "_JtAWJRfLdks"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(X_train, y_train, 'training')"
      ],
      "metadata": {
        "id": "zi-_JQqFtf1a",
        "outputId": "6c15fce1-7f21-48ad-de00-00ebda4d26bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes on training data:  0.8212281000170097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## h) `test_data`"
      ],
      "metadata": {
        "id": "-t08tf52SKkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the test data from CSV file\n",
        "test_data = pd.read_csv('covid-tweets-test.csv')\n",
        "test_data.columns = ['Label', 'Message', 'Sentiment']\n",
        "test_data.head()\n",
        "# Test our model by doing the same analysis to test_data\n",
        "filter_missing_values(test_data)\n",
        "tokenize(test_data)\n",
        "remove_url(test_data)\n",
        "remove_punctuation(test_data)\n",
        "convert_to_lowercase(test_data)\n",
        "stemming_tokens(test_data)\n",
        "remove_stopwords(test_data)\n",
        "X_test, y_test = split_tokens_and_label(test_data)\n",
        "X_test = convert_to_vector(X_test)\n",
        "predict(X_test, y_test, 'test')"
      ],
      "metadata": {
        "id": "ylgrKsxouCyr",
        "outputId": "43423671-1ab0-4d05-d46e-b5d669ba8605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes on test data:  0.8667719852553976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II"
      ],
      "metadata": {
        "id": "WNdrjeuYbgIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bearer_token=\"AAAAAAAAAAAAAAAAAAAAABjFsgEAAAAAlpTaLAR1wJ2sut2HNk8oY2r9u28%3DRWpfy37hyg15PEYEQJAQwhjS9S3RasSkc1WV35KH1FhBPfAgjF\""
      ],
      "metadata": {
        "id": "4GhWZV5PbhXX"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tweepy as tw\n",
        "\n",
        "# client = tw.Client(bearer_token=bearer_token)"
      ],
      "metadata": {
        "id": "QDSlC81IbqJ1"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ONLY RUN THIS CELL ONCE IN LAB SO AVOID GOING OVER THE RATE LIMIT FOR THIS ACCOUNT!\n",
        "\n",
        "# #Collect tweets (here, I get only 20)\n",
        "# search_words = '#toronto'\n",
        "\n",
        "# response = client.search_recent_tweets(search_words, max_results=100)\n",
        "# tweets = response.data"
      ],
      "metadata": {
        "id": "AYCYwJ87bz0d"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Number of tweets: {len(tweets)}')\n",
        "\n",
        "# # The result is an iterable\n",
        "# for tweet in tweets:\n",
        "#   print(tweet.text)\n",
        "\n",
        "# # Could also use a list comprehension"
      ],
      "metadata": {
        "id": "fVWxCTWqb5-J"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tweet_list = [tweet.text for tweet in tweets]\n",
        "# tweet_text = pd.DataFrame(tweet_list, columns = ['tweet'])\n",
        "\n",
        "# print(tweet_text.head(5))"
      ],
      "metadata": {
        "id": "p6qGNmHEcmom"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extract handles\n",
        "# handle_regex = '@[A-Za-z|0-9]+'\n",
        "\n",
        "# tweet_text['handles'] = tweet_text['tweet'].str.findall(handle_regex)\n",
        "# print(tweet_text.head(10))"
      ],
      "metadata": {
        "id": "ugieerxnc_UV"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the file path to save the DataFrame\n",
        "# file_path = 'twitter_data.txt'\n",
        "\n",
        "# # Write the DataFrame to a text file\n",
        "# tweet_text.to_csv(file_path, sep='\\t', index=False)\n",
        "\n",
        "# print(f\"DataFrame has been successfully written to '{file_path}'.\")"
      ],
      "metadata": {
        "id": "jdCca0z9dYK-"
      },
      "execution_count": 294,
      "outputs": []
    }
  ]
}